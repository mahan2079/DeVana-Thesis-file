\chapter{الگوریتم های اعمال شده در نرم افزار 
\lr{DeVana}
در نسخه 
\softwareVersion}

\section{الگوریتم ژنتیک پیشرفته}

با وجود پايه‌های نظری و پيچيدگی‌های الگوريتمی، الگوريتم‌های ژنتيک سنتی در مواجهه با مساله‌های بهينه‌سازی پيچيده و پربعد ــ مانند طراحی \lr{DVA} ــ با محدوديت‌های جدی روبه‌رو هستند. در اين بخش، اين محدوديت‌ها به‌صورت نظام‌مند تبيين می‌شوند تا هم بينش نظری و هم شواهد عملیِ لازم برای انگيزش توسعه‌ی ويژگی‌های پيشرفته‌ی \lr{GA} فراهم شود.

\subsection{محدوديت‌های نظری}

\subsubsection{گيرافتادن در بهينه‌های محلی}

الگوريتم‌های ژنتيک سنتی در منظر‌های برازندگی چندقله‌ای، مانند بهينه‌سازی \lr{DVA}، به‌شدت مستعد گيرافتادن در بهينه‌های محلی‌اند. فضای پارامتری 48بُعدی منظری نمايی از حالت‌های ممکن و شمار فراوانی از بهينه‌های محلی پديد می‌آورد که می‌تواند الگوريتم را پيش از دستيابی به بهينه‌ی سراسری متوقف کند.

ريشه‌ی مساله در ماهيت چشم‌انداز \lr{DVA} است: نواحی متمايز با عملکرد خوب، که با دره‌های عملکرد ضعيف از هم جدا شده‌اند. هر بهينه‌ی محلی می‌تواند به يک چيدمان معتبر \lr{DVA} با کاهش ارتعاش قابل قبول بيانجامد؛ اما تنها يک پيكربندی، بهينه‌ی واقعی است. اگر حوزه‌ی جذب يک بهينه‌ی محلی نسبت به فضای جست‌وجو بزرگ باشد، جمعيت به‌سادگی در آن ناحيه قفل می‌شود.

در \lr{DVA}، ترکيب‌های گوناگون نسبت‌های جرمی، سختی و ميرايی می‌توانند سطوح مشابهی از کاهش ارتعاش ايجاد کنند؛ در نتيجه چند راه‌حل معتبر شکل می‌گيرد. از سوی ديگر، برهم‌کنش‌های پيچيده‌ی 48 پارامتر، سطح‌های برازندگی پيچيده‌ای می‌سازند که گاهی تغييرات کوچک در بعضی ترکيب‌ها اثر بزرگ و در ترکيب‌های ديگر اثر ناچيز دارد.

تکيه‌ی \lr{GA} سنتی بر جست‌وجوی محلی از طريق ترکيب و جهش، آسيب‌پذيری در برابر اين دام را تشديد می‌کند: با همگرايی جمعيت به حوالی يک بهينه‌ی محلی، عملگرها عمدتاً همان حوالی را می‌کاوند و کمتر توان جهش به نواحی دوردست را دارند. نفرين بُعد نيز وضع را بدتر می‌کند: با افزايش بُعد، احتمال اين‌که يک جهش تصادفی به راه‌حل بهتر بينجامد، به‌شدت کاهش می‌يابد.

\subsubsection{همگرايی زودرس}

همگرايی زودرس از مهم‌ترين محدوديت‌های \lr{GA} سنتی است، به‌ويژه در مسائل پربعد. اين پديده وقتی رخ می‌دهد که تنوع ژنتيکی جمعيت سريعاً از دست برود و الگوريتم پيش از کاوش کافی، به راه‌حل‌های فروبهينه قفل شود.

سازوکارِ آن با گزينش آغاز می‌شود: افراد پُربرازندگی بيشتر برگزيده می‌شوند و به‌تدريج جمعيت همگن و کم‌تنوع می‌شود. در \lr{DVA}، يافتن يک راه‌حل «بد نيست» در نسل‌های اول باعث می‌شود الگوريتم به جای جست‌وجوی نواحی جايگزين، همان راه‌حل را صيقل دهد. انتخاب تورنمنتی، هرچند از نسبت‌برازندگی بادوام‌تر است، اما با همگن‌شدن جمعيت باز هم تنوع را سريع می‌کاهد. جهش که بايد تنوع بيافريند، با نزديک‌شدن جمعيت به يک بهينه‌ی محلی کم‌اثر می‌شود، چون جهش‌های دور از آن نقطه معمولاً برازندگی را بدتر می‌کنند و حذف می‌شوند.

\subsubsection{حساسيت شديد به تنظيمات پارامترها}

کارآيی \lr{GA} سنتی حساسيت زيادی به اندازه‌ی جمعيت، احتمال ترکيب، احتمال جهش و اندازه‌ی تورنمنت دارد. اين حساسيت در مسائل پربعد تشديد می‌شود، چون برهم‌کنش ميان اين پارامترها ديناميک‌های غيرخطی و پيش‌بينی‌ناپذيری می‌سازد. تغيير کوچک در يک پارامتر می‌تواند نيازمند بازتنظيم ساير پارامترها باشد تا توازن اکتشاف/بهره‌برداری حفظ شود.

\subsubsection{ناترازی اکتشاف/بهره‌برداری با پارامترهای ثابت}

\lr{GA} سنتی معمولاً از پارامترهای ثابت در تمام فرآيند استفاده می‌کند. در مراحل آغازين، اکتشاف گسترده لازم است (جمعيت بزرگ، جهش بالاتر، فشار گزينش کمتر) و در مراحل انتهايی بهره‌برداری دقيق (جهش پايين، فشار بيشتر)؛ اما پارامترهای ثابت نمی‌توانند به اين نيازهای در حال تغيير پاسخ دهند. نتيجه، جست‌وجوی ناکارا و هم به زيان سرعت و هم کيفيت است.

\subsection{محدوديت‌های عملی}

\subsubsection{هزينه‌ی محاسباتی بالا}

در \lr{DVA}، هر ارزيابی برازندگی نيازمند تحليل \lr{FRF}، وارون‌سازی/حل ماتريسی و استخراج سنجه‌های کارکردی روی طيف بسامدی است؛ بنابراين هر فرد گران است. جمعيت‌های بزرگ و نسل‌های زياد، تعداد ارزيابی‌ها را به هزاران/ده‌ها هزار می‌رساند. با افزايش بُعد، هم هزينه‌ی هر ارزيابی و هم تعداد ارزيابی‌های لازم بالا می‌رود و هزينه دوچندان می‌شود.

\subsubsection{پيچيدگی تنظيم پارامتر}

تنظيم بهينه‌ی اندازه‌ی جمعيت، احتمال ترکيب، احتمال جهش و اندازه‌ی تورنمنت خود به يک مساله‌ی بهينه‌سازی تبديل می‌شود. وابستگی شديد اين پارامترها به ويژگی‌های مساله (چندرأسی بودن، زبری چشم‌انداز، بُعد) و برهم‌کنش‌های درونی‌شان، تنظيم نظام‌مند را دشوار و پرهزينه می‌کند؛ به‌ويژه وقتی هر اجرای بهينه‌سازی ساعت‌ها/روزها طول بکشد.

\subsubsection{فقدان سازگارسازی مسئله‌محور}

\lr{GA} سنتی سازوکاری برای بهره‌گيری از دانش دامنه ندارد: قيدهای فيزيکی (جرم‌های مثبت، ميرايی نامنفی، ترکيب‌های نامطلوب) يا نشانه‌های منظری (مرزهای فيزيکی/مصنوعی بهينه‌های محلی) را نمی‌آموزد و رفتارش را بر آن اساس تنظيم نمی‌کند. در نتيجه نمی‌تواند ترجيحات طراح يا قيود اجرايی را به‌طور پويا در جست‌وجو بگنجاند.

\subsubsection{مبادله‌ی سرعت همگرايی و کيفيت راه‌حل}

افزايش فشار گزينش سرعت را بالا می‌برد اما ريسک همگرايی زودرس را زياد می‌کند؛ جهش‌های زياد تنوع را حفظ می‌کند اما راه‌حل‌های خوب را مخدوش می‌سازد؛ جمعيت‌های بزرگ اکتشاف را بهبود می‌دهند اما هزينه و زمان را بالا می‌برند. با پارامترهای ثابت، رسيدن هم‌زمان به سرعت بالا و کيفيت عالی دشوار است، به‌خصوص در مسائل پربعد مانند \lr{DVA}.

\subsection{تحليل کارکرد}

\subsubsection{نرخ همگرايی}

نرخ همگرايی تابع فشار گزينش، نرخ جهش، اندازه‌ی جمعيت و ويژگی‌های چشم‌انداز است. در \lr{GA} سنتی، ثابت‌بودن اين پارامترها مانع از تنظيم پويا برای رسيدن به نرخ‌های بهينه در مراحل مختلف می‌شود: گاهی زيادی سريع (به سمت فروبهينه)، گاهی زيادی کند (هزينه‌ی بالا).

\subsubsection{مکانيزم‌های از دست‌دادن تنوع}

فشار گزينش، ترکيب ميان والدين مشابه و حذف جهش‌های دور از بهينه‌ی محلی، تنوع را سريع می‌کاهد. با کاهش تنوع، کارآيی جهش در ايجاد جهش‌های سازنده کم می‌شود و يک حلقه‌ی بازخوردی به سمت همگرايی زودرس شکل می‌گيرد. در فضاهای پربعد، حفظ تنوع به جمعيت‌های بسيار بزرگ نيازمند است که از نظر محاسباتی عملياتی نيست.

\subsubsection{اثرهای برهم‌کنش پارامترها}

بهينه‌ی نرخ جهش به اندازه‌ی جمعيت وابسته است؛ بهينه‌ی احتمال ترکيب به فشار گزينش (اندازه‌ی تورنمنت)؛ و همه به توپوگرافی برازندگی وابسته‌اند. اين برهم‌کنش‌های غيرخطی و وابسته به مساله، تنظيم مؤثر را دشوار و ناپايداری عملکرد را محتمل می‌کند.

\subsubsection{محدوديت‌های مقياس‌پذيری}

با افزايش بُعد، اندازه‌ی فضای جست‌وجو و هزينه‌ی هر ارزيابی نمايی رشد می‌کند، تنوع به‌سختی حفظ می‌شود، و نرخ همگرايی افت می‌کند. در \lr{DVA} با 48 پارامتر، اين عوامل دست‌به‌دست هم می‌دهند تا \lr{GA} سنتی را از نظر عملیاتی ناکارا کنند.

\paragraph{جمع‌بندی و انگيزه برای ويژگی‌های پيشرفته}
مجموع اين محدوديت‌ها نياز به ويژگی‌های پيشرفته را روشن می‌کند: \emph{کنترل‌های تطبيقی} برای اندازه‌ی جمعيت، نرخ جهش و احتمال ترکيب؛ \emph{روش‌های جانشين‌ياب} برای کاهش هزينه‌ی ارزيابی؛ \emph{بذرگذاری هوشمند} بر پايه‌ی طرح‌های نمونه‌برداری و مدل‌های يادگيری؛ و \emph{سياست‌های حفظ تنوع} برای جلوگيری از همگرايی زودرس. در بخش‌های بعد، اين امکانات و يکپارچگی آن‌ها با \lr{GA} برای بهينه‌سازی \lr{DVA} تشريح می‌شود.


% نکته پرامبل (در صورت نیاز):
% \usepackage{amsmath, amssymb}
% \usepackage{algorithm}
% \usepackage{algpseudocode} % در صورت ترجیح به شبه‌کد؛ این متن از enumerate در محیط algorithm استفاده می‌کند.




\section{مرور قابليت‌هاي پيشرفته}

\lr{DeVana} الگوريتم پايه \lr{GA} را با كنترل‌گرها و نمونه‌بردارهايي كه به‌صورت آنلاين سازگار مي‌شوند گسترش مي‌دهد: 
(i) \textbf{كنترل تطبيقي عملگرها} از طريق يك بَنديتِ يادگيري ماشيني \lr{(ML bandit)} يا يك عاملِ \lr{RL} سبك كه مقادير \(\text{cxpb}\)، \(\text{mutpb}\) و اندازه جمعيت \(N\) را نسل‌به‌نسل تنظيم مي‌كند؛ 
(ii) \textbf{بذرگذاري پيشرفته} با طرح‌هاي كم‌ناهمخوان \lr{Sobol}/\lr{LHS} و يك \textbf{NeuralSeeder} كه با استفاده از \lr{UCB} يا \lr{EI} نواحي اميدبخش را مي‌آموزد؛ 
(iii) \textbf{غربالگريِ كمكي مبتني بر جانشين} كه با يك جانشين \lr{KNN} و اكتشاف مبتني بر نوآوري (تازگي)، فرزندان را پيش‌فيلتر مي‌كند. 
تمام سازوكارها به پارامترهاي ثابت و كران‌ها احترام مي‌گذارند.

\subsection{كنترل‌گر بَنديتِ يادگيري ماشيني براي سازگارسازي پارامترها}

كنترل‌گر يك فضاي عمل گسسته \(\mathcal{A}=\{(\delta_{\text{cx}},\delta_{\mu},\pi)\}\) تعريف مي‌كند كه شامل تغييرات نسبيِ \(\text{cxpb}\) و \(\text{mutpb}\) و يك ضريبِ مقياس براي اندازه جمعيت است. در نسل \(t\)، عمل زير انتخاب مي‌شود
\begin{equation}
    a_t\;=\;\arg\max_{a\in\mathcal{A}}\Big[ \hat{R}_t(a)\; +\; c\,\sqrt{\tfrac{\ln t}{N_t(a)}} \Big], \label{Eq.ucb}
\end{equation}
كه در آن \(\hat{R}_t(a)\) پاداشِ ميانگين مشاهده‌شده براي عمل \(a\)، \(N_t(a)\) تعداد دفعات اجراي آن، و \(c>0\) كنترل‌گر ميزان اكتشاف است. عملِ انتخاب‌شده پارامترها را به‌صورت زير به‌روز مي‌كند
\begin{align}
    \text{cxpb}_{t+1}&=\operatorname{clip}(\text{cxpb}_t\,(1+\delta_{\text{cx}}),\;[\text{cxpb}_{\min},\text{cxpb}_{\max}]),\\
    \text{mutpb}_{t+1}&=\operatorname{clip}(\text{mutpb}_t\,(1+\delta_{\mu}),\;[\text{mutpb}_{\min},\text{mutpb}_{\max}]),\\
    N_{t+1}&=\operatorname{round}(\operatorname{clip}(\pi\,N_t,\;[N_{\min},N_{\max}])).
\end{align}

\paragraph{شكل‌دهي پاداش}
طبق پياده‌سازي، پاداش توازن ميان بهبود، سرعت، تنوع و هزينه را برقرار مي‌كند:
\begin{equation}\label{Eq.bandit_reward}
    R_t\;=\;\frac{\max\{0,\,f^{\star}_{t-1}-f^{\star}_{t}\}}{\max\{\epsilon,\,T_t\}}\,\frac{1}{\max\{1,\,E_t\}}\; -\; w_{\text{div}}\,\big|\mathrm{CV}_t-\mathrm{CV}^{\text{target}}\big|,
\end{equation}
كه در آن \(f^{\star}_t\) بهترين برازندگيِ نسل \(t\)، \(T_t\) زمان نسل، \(E_t\) تعداد ارزيابي‌ها و \(\mathrm{CV}_t=\tfrac{\sigma_t}{|\mu_t|+\epsilon}\) ضريب تغييرات برازندگي است. يك برآوردگر آميخته \(\tilde R_t= w_{\text{hist}}\,\hat{R}_{t-1}(a)+w_{\text{cur}}\,R_t\) به پايداريِ به‌روزرسانی‌ها كمك مي‌كند.

\begin{algorithm}[H]
\caption{كنترل‌گر \lr{ML-Bandit} (در هر نسل)}
\begin{algorithmic}[1]
\STATE محاسبه آمار \(\mu_t,\sigma_t,f^{\star}_t,T_t,E_t\) از نسلِ تمام‌شده.
\STATE براي هر \(a\in\mathcal{A}\)، امتياز \lr{UCB} را طبق معادله~\eqref{Eq.ucb} محاسبه و \(a_t\) را انتخاب كنيد.
\STATE \((\text{cxpb},\text{mutpb},N)\) را با عمل انتخاب‌شده و با كليپ‌كردنِ كران‌ها به‌روز كنيد.
\STATE \(R_t\) را طبق معادله~\eqref{Eq.bandit_reward} مشاهده كرده و شمارش‌ها و ميانگين‌ها را براي \(a_t\) به‌روز كنيد.
\end{algorithmic}
\end{algorithm}

\subsection{كنترل مبتني بر \lr{Reinforcement Learning} براي پارامترهاي \lr{GA}}

يك عاملِ فشرده \lr{Q-learning} با سياستِ \(\epsilon\)-حريصانه، عمل‌هاي \(a\in\mathcal{A}\) را با توجه به حالتِ درشت \(s\) (مانند «بهبود/عدم‌بهبود») انتخاب مي‌كند. به‌روزرسانی به صورت زير است:
\begin{equation}
    Q(s,a)\leftarrow Q(s,a)+\alpha\,\big(R+\gamma\max_{a'}Q(s',a')-Q(s,a)\big),
\end{equation}
كه در آن نرخ يادگيري \(\alpha\)، ضريب تنزيل \(\gamma\) و اكتشاف \(\epsilon\) در هر نسل كاهش مي‌يابند. نگاشتِ عمل‌ها به سه‌تايي‌هاي \((\delta_{\text{cx}},\delta_{\mu},\pi)\) همانند قبل است و با رعايت كران‌ها كليپ مي‌شوند.

\begin{algorithm}[H]
\caption{كنترل‌گر \lr{RL} (در هر نسل)}
\begin{algorithmic}[1]
\STATE مشاهده حالت \(s_t\) (مثلاً \(\mathbb{1}[f^{\star}_t<f^{\star}_{t-1}]\)).
\STATE با احتمال \(\epsilon\) عمل تصادفي \(a_t\) را انتخاب كنيد، وگرنه \(\arg\max_a Q(s_t,a)\).
\STATE \((\text{cxpb},\text{mutpb},N)\) را با عملِ \(a_t\) و كليپ‌كردنِ كران‌ها به‌روز كنيد.
\STATE پاداش \(R_t\) را طبق \eqref{Eq.bandit_reward} دريافت كرده، حالت \(s_{t+1}\) را مشاهده و \(\,Q\) را به‌روز كنيد.
\STATE كاهش اكتشاف: \(\epsilon\leftarrow\epsilon\cdot\epsilon_{\text{decay}}\).
\end{algorithmic}
\end{algorithm}

\subsection{بذرگذاريِ \lr{Sobol} و \lr{Latin Hypercube}}

براي \(d=P\) پارامتر آزاد با كران‌هاي \(\ell_i,u_i\)، يك موتور \lr{QMC} نقاط \(\mathbf{z}_k\in[0,1]^d\) را با \lr{Sobol} يا \lr{LHS} توليد كرده و سپس به بازه‌ها مقياس مي‌كند:
\begin{equation}
    x_{k,i}\;=\;\ell_i + z_{k,i}\,(u_i-\ell_i),\quad i=1,\dots,d,\;k=1,\dots,m,
\end{equation}
و مختصاتِ ثابت را بازنويسي مي‌كند. بذرگذاريِ \lr{QMC} نسبت به تصادفيِ محض پوشش فضايي بهتري فراهم مي‌كند.

\subsection{بذرگذاري جمعيت با شبكه عصبي \lr{(NeuralSeeder)}}

\lr{NeuralSeeder} يك پايگاه‌داده \(\mathcal{D}=\{(\mathbf{x}^{(n)}, y^{(n)})\}\) از نقاطِ ارزيابي‌شده نگه مي‌دارد و يك انجمنِ سبك را براي مدل‌سازيِ \(y\approx f(\mathbf{x})\) آموزش مي‌دهد. اين روش با بهينه‌سازيِ يك تابع اكتساب مانند \lr{UCB} يا \lr{EI} بر روي يك استخرِ كانديدا، نمونه‌ها را پيشنهاد مي‌كند؛ كسرِ اكتشاف \(\epsilon\) و مقياسِ \(\beta\) در \lr{UCB} به‌صورت آنلاين سازگار مي‌شوند:
\begin{align}\label{eq:UCBEI}
    \text{UCB}(\mathbf{x}) &= \mu(\mathbf{x}) - \beta\,\sigma(\mathbf{x}) \quad \text{(مسئله مينيمم‌سازي)},\\
    \text{EI}(\mathbf{x}) &= \mathbb{E}\big[\max\{0, f^{\star}-Y(\mathbf{x})\}\big].
\end{align}
يك قيدِ تنوع (حداقل فاصله در فضاي نرمال‌شده) از فروريزش به يك مُد جلوگيري مي‌كند. هرگاه كنترل‌گر اندازه جمعيت را افزايش دهد، در صورت كفايت داده، افرادِ اضافي از \lr{NeuralSeeder} تأمين مي‌شوند؛ در غير اين صورت به روش بذرگذاريِ پيكربندي‌شده بازگشت مي‌شود.

\subsection{ارزيابي برازندگي با كمك مدلِ جانشين}

براي كاهش فراخواني‌هاي \lr{FRF}، يك جانشين \lr{KNN} فرزندان را پيش‌غربال مي‌كند. اگر \(\tilde{\mathbf{x}}\) يك كانديدا باشد و مختصات نرمال‌شده \(z_i=(x_i-\ell_i)/(u_i-\ell_i)\) تعريف شوند، پيش‌بين به صورت زير است:
\begin{equation}
    \hat f(\tilde{\mathbf{x}})= \frac{1}{k}\sum_{(\mathbf{x}^{(n)},y^{(n)})\in\mathcal{N}_k(\tilde{\mathbf{x}})} y^{(n)},\quad \mathcal{N}_k(\tilde{\mathbf{x}})=\arg\min_{\mathcal{S},\;|\mathcal{S}|=k}\sum_{(\mathbf{x},\cdot)\in\mathcal{S}}\lVert \mathbf{z}-\tilde{\mathbf{z}}\rVert_2.
\end{equation}
يك استخر با اندازه \(M=\lceil \phi\,Q\rceil\) (با \(Q\) فرزند نامعتبر و عامل استخر \(\phi\ge1\)) از طريق كلون‌كردن و اعمال عملگرهاي ژنتيكيِ سبك ساخته مي‌شود؛ برترين‌ها برحسب \(\hat f\) \emph{استثمار} شده و يك زيرمجموعه \emph{اكتشافي} با بيشينه‌كردنِ تازگي اضافه مي‌گردد:
\begin{equation}
    \mathcal{N}(\tilde{\mathbf{x}})=\min_{\mathbf{x}^{(n)}\in\mathcal{D}}\lVert \tilde{\mathbf{z}}-\mathbf{z}^{(n)}\rVert_2.
\end{equation}
تنها زيرمجموعه انتخاب‌شده با \lr{FRF} ارزيابي مي‌شود و بقيه حذف مي‌گردند؛ وقتي \lr{FRF} گران است، اين كار صرفه‌جوييِ قابل توجه ايجاد مي‌كند.

\begin{algorithm}[H]
\caption{غربال جانشين در هر نسل}
\begin{algorithmic}[1]
\REQUIRE مجموعه فرزندان نامعتبر \(\mathcal{U}\) با اندازه \(Q\)، عامل استخر \(\phi\)، كسر اكتشاف \(\eta\)، \lr{KNN} با \(k\)
\STATE ساخت استخر \(\mathcal{P}\) با اندازه \(M=\max\{Q,\lceil\phi Q\rceil\}\) از طريق كلون‌كردنِ \(\mathcal{U}\) و اعمال تركيبي/جهشيِ سبك (با رعايت كران‌ها و ژن‌هاي ثابت).
\STATE پيش‌بينيِ \(\hat f\) براي تمام \(\mathbf{x}\in\mathcal{P}\) و مرتب‌سازيِ صعودي.
\STATE انتخاب \(q=Q\) كانديدايِ استثماري با كم‌ترين \(\hat f\).
\STATE از باقيمانده، \(\eta q\) كانديدايِ با بيش‌ترين تازگي را انتخاب و به مجموعه برگزيده بيفزاييد.
\STATE ارزيابيِ \lr{FRF} فقط براي مجموعه برگزيده؛ در صورت نياز، شكاف‌ها با برترين‌هاي ارزيابي‌شده پر شوند.
\end{algorithmic}
\end{algorithm}

\subsection{نرخ‌هاي تطبيقي قديمي (\lr{Legacy})}

به‌عنوان پشتيبان، يك قاعده تجربي \((\text{cxpb},\text{mutpb})\) را بر اساس تنوع \(\sigma/|\mu|\) و شمارنده ركود تنظيم مي‌كند: در تنوع پايين، جهش افزايش و تركيب كاهش مي‌يابد؛ در تنوع بالا برعكس؛ و اين تنظيمات به‌صورت دوره‌اي اعمال مي‌شوند.



\section{ویژگی‌های پیشرفته الگوریتم ژنتیک}

این بخش، ویژگی‌های پیشرفته پیاده‌سازی‌شده در سامانه \lr{GAWorker.py} را معرفی می‌کند که به‌طور مستقیم به محدودیت‌های بنیادینِ \lr{GA}‌های سنتی پاسخ می‌دهند. هر ویژگی برای ارتقای جنبه‌ای مشخص از فرآیند بهینه‌سازی طراحی شده و در عین حال با چارچوب هسته‌ای \lr{GA} یکپارچگی بی‌دردسری دارد.

\subsection{کنترل‌گر یادگیری تقویتی}

کنترل‌گرِ یادگیریِ تقویتی چارچوب \lr{Q-Learning} را برای تنظیم تطبیقیِ پارامترهای \lr{GA} بر پایه بازخورد عملکردِ برخط به‌کار می‌گیرد. این رویکرد نسبت به روش‌های با پارامترِ ثابت، گامی معنادار به‌پیش است؛ زیرا \lr{GA} می‌تواند پیکربندی‌های بهینه پارامتری را از راه تجربه بیاموزد.

\subsubsection{زیربنای ریاضی \lr{Q-Learning}}

در \lr{Q-Learning} یک جدول \lr{Q} نگهداری می‌شود که پاداشِ تجمعیِ مورد انتظار را برای هر جفتِ وضعیت–کنش ذخیره می‌کند. مقدار \lr{Q}، پاداشِ بلندمدتِ مورد انتظار هنگام انجام کنش \(a\) در وضعیت \(s\) را نشان می‌دهد:
\begin{equation}\label{Eq.q_table_definition}
Q(s, a) = \mathbb{E}\!\left[\sum_{k=0}^{\infty} \gamma^k R_{t+k+1} \,\middle|\, S_t = s,\; A_t = a\right]
\end{equation}
که در آن \(\gamma \in [0,1]\) ضریب تنزیل است و اهمیت پاداش‌های آینده را نسبت به پاداش‌های آنی تعیین می‌کند؛ \(\gamma\) بزرگ‌تر یعنی تأکید بر افقِ بلندمدت.

قاعده به‌روزرسانیِ \lr{Q-Learning} از یادگیریِ اختلافِ زمانی پیروی می‌کند:
\begin{equation}\label{Eq.q_learning_update}
Q(s, a) \leftarrow Q(s, a) + \alpha \big[ R_t + \gamma \max_{a'} Q(s', a') - Q(s, a) \big]
\end{equation}
که در آن \(\alpha \in [0,1]\) نرخِ یادگیری است و \(\max_{a'} Q(s', a')\) بیشینه پاداشِ مورد انتظار از وضعیتِ بعدی است.

\subsubsection{طراحی فضای وضعیت}

فضای وضعیت برای ثبتِ دینامیک‌های بنیادینِ همگراییِ \lr{GA} فشرده‌سازی شده است:
\begin{equation}\label{Eq.rl_state_space}
\mathcal{S} = \{0,\,1\}
\end{equation}
که:
\begin{itemize}
\item وضعیت 0: عدمِ بهبود در نسل جاری (رکود)
\item وضعیت 1: وقوع بهبود (یافتنِ برازندگی بهتر)
\end{itemize}
گذارِ وضعیت بر مبنای تشخیصِ بهبود تعریف می‌شود:
\begin{equation}\label{Eq.state_transition}
s_{t+1} =
\begin{cases}
1 & \mtext{اگر } f_{best}^{t+1} < f_{best}^{t} \\
0 & \mtext{در غیر این صورت}
\end{cases}
\end{equation}
که \(f_{best}^{t}\) بهترین مقدارِ برازندگی در نسل \(t\) است.

\subsubsection{طراحی فضای کنش}

فضای کنش، کنترلِ ریزدانه بر پارامترهای \lr{GA} را با پوشش جامعِ تنظیمات فراهم می‌کند:
\begin{equation}\label{Eq.rl_actions}
\mathcal{A} = \{(dcx,\; dmu,\; pm)\;|\; dcx \in \Delta_{cx},\; dmu \in \Delta_{mu},\; pm \in \mathcal{P}\}
\end{equation}
افزاینده‌های نسبیِ ترکـیب و جهش با دانه‌بندی بالا تعریف می‌شوند:
\begin{equation}\label{Eq.delta_sets}
\Delta_{cx} = \Delta_{mu} = \{-1.0,\; -0.9,\; -0.8,\; \ldots,\; -0.01,\; 0.0,\; 0.01,\; \ldots,\; 0.9,\; 1.0\}
\end{equation}
ضرب‌کننده‌های جمعیت امکانِ تغییرات کوچک تا بزرگ را فراهم می‌کنند:
\begin{equation}\label{Eq.pop_multipliers}
\mathcal{P} = \{0.01,\; 0.02,\; \ldots,\; 0.98,\; 1.0,\; 1.02,\; \ldots,\; 10.0\}
\end{equation}

\subsubsection{راهبرد اکتشاف \lr{Epsilon-Greedy}}

سیاستِ انتخابِ کنش با رویکردِ \lr{epsilon-greedy} توازنِ اکتشاف/بهره‌برداری را برقرار می‌کند:
\begin{equation}\label{Eq.epsilon_greedy}
\pi(s) =
\begin{cases}
\mtext{یک کنشِ تصادفی } a \in \mathcal{A} & \mtext{با احتمال } \epsilon \\
\arg\max_{a \in \mathcal{A}} Q(s, a)     & \mtext{با احتمال } 1-\epsilon
\end{cases}
\end{equation}
نرخِ اکتشاف \(\epsilon\) به‌صورت نمایی کاهش می‌یابد:
\begin{equation}\label{Eq.epsilon_decay}
\epsilon_{t+1} = \epsilon_t \times 0.95
\end{equation}

\subsubsection{طراحی تابع پاداش}

تابع پاداش، چند هدفِ بهینه‌سازی را موازنه می‌کند:
\begin{equation}\label{Eq.rl_reward}
R_t = \frac{\mtext{improvement}}{\mtext{time}} \times \frac{1}{\mtext{effort}}
\;-\;
\lambda \times \big|\mtext{diversity} - \mtext{target\_diversity}\big|
\end{equation}
که در آن:
\begin{itemize}
\item \(\mtext{improvement} = \max(0,\; f_{best}^{t-1} - f_{best}^{t})\) میزانِ بهبودِ برازندگی است،
\item \(\mtext{time}\) زمان اجرای نسل،
\item \(\mtext{effort} = \max(1.0,\; \mtext{evaluations\_this\_generation})\) سنجه هزینه محاسباتی،
\item \(\mtext{diversity} = \sigma / \mu\) ضریبِ تغییرپذیری (نسبت انحراف معیار به میانگین)،
\item \(\lambda\) وزنِ جریمه انحراف از تنوعِ هدف است.
\end{itemize}

\subsubsection{تنظیم پارامتر و اعمال کران‌ها}

پس از انتخابِ کنش، پارامترهای جدید محاسبه و در کران‌های معتبر محدود می‌شوند:
\begin{equation}\label{Eq.parameter_adjustment}
\begin{aligned}
\mtext{new\_cx}  &= \min(\mtext{cx\_max},\; \max(\mtext{cx\_min},\; \mtext{current\_cx} \times (1 + dcx))) \\
\mtext{new\_mu}  &= \min(\mtext{mu\_max},\; \max(\mtext{mu\_min},\; \mtext{current\_mu} \times (1 + dmu))) \\
\mtext{new\_pop} &= \min(\mtext{pop\_max},\; \max(\mtext{pop\_min},\; \mtext{round}(\mtext{current\_pop} \times pm)))
\end{aligned}
\end{equation}

\subsubsection{الگوریتم یکپارچه‌سازی با تغییر اندازه جمعیت}

\begin{algorithm}
\caption{یکپارچه‌سازی کنترل‌گر \lr{RL} با \lr{GA}}
\begin{enumerate}
\item \textbf{مقداردهی اولیه}: جدول \lr{Q} برای همه جفت‌های وضعیت–کنش با صفر
\item \textbf{تنظیم حالت آغازین}: \(s_0 = 0\)، نرخ اکتشاف \(\epsilon = 0.2\)
\item \textbf{برای هر نسل \(t\)}:
  \begin{enumerate}
  \item \textbf{گزینش کنش} با سیاست \lr{epsilon-greedy}: \(a_t = \pi(s_t)\)
  \item \textbf{استخراج تنظیمات} از کنش: \((dcx,\; dmu,\; pm) = a_t\)
  \item \textbf{محاسبه پارامترهای جدید} و اِعمال کران‌ها با \eqref{Eq.parameter_adjustment}
  \item \textbf{تغییر اندازه جمعیت} اگر \(pm \neq 1.0\):
    \begin{enumerate}
    \item \textbf{اگر کوچک‌سازی} (\(pm<1.0\)): گزینش بهترین‌ها با انتخاب تورنمنتی
    \item \textbf{اگر بزرگ‌سازی} (\(pm>1.0\)): تولید افراد جدید با بذرگذاری عصبی (در صورت دسترس)
    \item \textbf{ارزیابی فوری} افراد جدید برای درج برازندگی معتبر
    \end{enumerate}
  \item \textbf{اجرای یک نسل \lr{GA}} با پارامترهای تنظیم‌شده (گزینش، ترکـیب، جهش، ارزیابی)
  \item \textbf{محاسبه پاداش} \(R_t\) طبق \eqref{Eq.rl_reward}
  \item \textbf{تعیین وضعیت بعدی} \(s_{t+1}\) طبق \eqref{Eq.state_transition}
  \item \textbf{به‌روزرسانی جدول \lr{Q}} با \eqref{Eq.q_learning_update}
  \item \textbf{کاهش اکتشاف}: \(\epsilon \leftarrow \epsilon \times 0.95\)
  \item \textbf{گذارِ وضعیت}: \(s_t \leftarrow s_{t+1}\)
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{بذرگذاری مبتنی بر شبکه عصبی}

سامانه بذرگذاریِ عصبی با آموزشِ شبکه‌ای بر روی ترکیب‌های موفقِ پارامترها، کیفیتِ جمعیتِ اولیه و نمونه‌های الحاقی را ارتقا می‌دهد.

\subsubsection{معماری شبکه عصبی}

بذرگذارِ عصبی از یک شبکه پیش‌خورِ پیکربندی‌پذیر استفاده می‌کند:
\begin{itemize}
\item لایه ورودی: 48 گره (پارامترهای \lr{DVA})
\item لایه‌های پنهان: 2 لایه، هر یک با 96 نورون (قابل تنظیم)
\item لایه خروجی: 1 گره (پیش‌بینی برازندگی)
\item فعال‌ساز: \lr{ReLU} در لایه‌های پنهان، خطی در خروجی
\item \lr{Dropout}: برابر با \(0.1\) برای منظم‌سازی
\item میرایی اوزان: \(10^{-4}\) (\lr{L2})
\end{itemize}

\subsubsection{فرآیند آموزش}

شبکه به‌صورت افزایشی حین بهینه‌سازی آموزش می‌بیند:
\begin{algorithm}
\caption{فرآیند آموزش بذرگذارِ عصبی}
\begin{enumerate}
  \item دادهٔ آموزشیِ اولیه: \(X_{\mtext{train}} \leftarrow \emptyset\)، \(y_{\mtext{train}} \leftarrow \emptyset\).
  \item \textbf{برای هر نسل}:
    \begin{enumerate}
      \item گردآوریِ بردارهایِ پارامتر: \(X \leftarrow\) جمعیتِ جاری.
      \item گردآوریِ برازندگی‌ها: \(y \leftarrow\) برازندگیِ جمعیتِ جاری.
      \item افزودن به آموزش: \(X_{\mtext{train}} \pluseq X\)، \(y_{\mtext{train}} \pluseq y\).
      \item \textbf{اگر} \(|X_{\mtext{train}}| > 50\) و بذرگذار در دسترس:
        \begin{enumerate}
          \item آموزشِ شبکه برای \(8\) دوره (قابل تنظیم).
          \item محدودیتِ زمانیِ هر آموزش: \(\approx 750\)\,\munit{ms}.
          \item به‌روزرسانیِ بذرگذار با مدلِ آموزش‌دیده.
          \item ثبتِ شاخص‌ها (زمان، تعدادِ دوره، \(\beta\)، اندازهٔ مخزن).
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{algorithm}


\subsubsection{توابع اکتساب}

چند تابع اکتساب برای موازنه اکتشاف/بهره‌برداری پشتیبانی می‌شود.

\textbf{کران اطمینان بالایی (\lr{UCB})}:
\begin{equation}\label{Eq.neural_ucb}
\mtext{UCB}(x) = \mu(x) + \kappa \cdot \sigma(x)
\end{equation}
در آن \(\mu(x)\) برازندگیِ پیش‌بینی‌شده و \(\sigma(x)\) عدم‌قطعیتِ پیش‌بینی و \(\kappa\) کنترل‌کننده موازنه است.

\textbf{بهبودِ مورد انتظار (\lr{EI})}:
\begin{equation}\label{Eq.neural_ei}
\mtext{EI}(x) = \mathbb{E}\big[\max(f(x) - f(x^{+}),\,0)\big]
\end{equation}
که \(x^{+}\) بهترین مشاهده موجود است.

\subsubsection{پارامتر \(\kappa\) تطبیقی}

پارامتر اکتشاف با رکود سازگار می‌شود:
\begin{equation}\label{Eq.adaptive_beta}
\kappa = \kappa_{\min} + (\kappa_{\max} - \kappa_{\min}) \cdot \min\!\left(1.0,\; \frac{S}{S_{\mtext{limit}}}\right)
\end{equation}
که \(S\) شمارنده رکود و \(S_{\mtext{limit}}\) آستانه آن است.

\subsubsection{الگوریتم یکپارچه‌سازی}

بذرگذاریِ عصبی با تغییر اندازه جمعیت تلفیق می‌شود:
\begin{algorithm}
\caption{بذرگذاریِ عصبی در گسترش جمعیت}
\begin{enumerate}
\item \textbf{تابع} \texttt{resize\_population(pop, new\_size)}:
  \begin{enumerate}
  \item \textbf{اگر} \(\mtext{new\_size} > |pop|\) و بذرگذار آموزش‌دیده است:
    \begin{enumerate}
    \item \(extra \leftarrow \mtext{new\_size} - |pop|\)
    \item \(best\_y \leftarrow \min\) برازندگی در جمعیتِ جاری
    \item \(seeds \leftarrow \) \texttt{neural\_seeder.propose}\((extra,\, \beta,\, best\_y,\, \epsilon)\)
    \item \textbf{برای هر} دانه: ساخت فردِ جدید و افزودن به جمعیت
    \item ارزیابی افرادِ جدید
    \end{enumerate}
  \item \textbf{در غیر این‌صورت}: بذرگذاری پیش‌فرض (تصادفی/سوبول/\lr{LHS})
  \item \textbf{بازگشت}: جمعیتِ تغییر اندازه‌داده‌شده
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{غربال‌گریِ یاری‌گرفته با جانشین}

در این سازوکار، رگرسیونِ \lr{KNN} برای پیش‌بینیِ برازندگی به‌کار می‌رود تا تنها افرادِ امیدبخش برای ارزیابیِ واقعی گزینش شوند و هزینه محاسباتی به‌شدت کاهش یابد.

\subsubsection{مدل جانشینِ \lr{KNN}}

پیش‌بینیِ برازندگی چنین است:
\begin{equation}\label{Eq.knn_prediction}
\hat{f}(x) = \frac{1}{k} \sum_{i=1}^{k} f(x_i)
\end{equation}
که \(x_i\)‌ها \(k\) همسایه نزدیکِ \(x\) در فضای پارامتر و معمولاً \(k=5\) است (قابل تنظیم).

\subsubsection{راهبرد اکتشاف/بهره‌برداری}

امتیازِ گزینش ترکیبی از بهره‌برداری و تازگی است:
\begin{equation}\label{Eq.surrogate_selection}
\mtext{Selection Score} = \alpha \cdot \mtext{Exploitation Score} + (1-\alpha) \cdot \mtext{Novelty Score}
\end{equation}
که \(\alpha = 0.85\) ترجیحِ بهره‌برداری (85\%) نسبت به اکتشاف (15\%) را نشان می‌دهد.

\paragraph{امتیازِ بهره‌برداری}:
\begin{equation}\label{Eq.exploitation_score}
\mtext{Exploitation Score} = -\hat{f}(x)
\end{equation}
برازندگیِ پیش‌بینی‌شده کمتر (بهتر) امتیازِ بالاتری می‌گیرد.

\paragraph{امتیازِ تازگی}:
\begin{equation}\label{Eq.novelty_score}
\mtext{Novelty Score} = \min_{x' \in X_{\mtext{train}}} \|x - x'\|
\end{equation}
که \(X_{\mtext{train}}\) مجموعه بردارهایِ ارزیابی‌شده قبلی است.

\subsubsection{الگوریتم یکپارچه‌سازی}

\begin{algorithm}
\caption{غربال‌گری یاری‌گرفته با جانشین}
\begin{enumerate}
\item \textbf{تابع} \texttt{evaluate\_with\_surrogate(invalid\_individuals)}:
  \begin{enumerate}
  \item \textbf{اگر} مدلِ جانشین آموزش ندیده: ارزیابیِ کامل، آموزش مدل و بازگشت
  \item \(pool\_size \leftarrow \texttt{surrogate\_pool\_factor} \times |invalid \_individuals|\)
  \item تولید مخزنِ نامزد با اغتشاشِ افرادِ نامعتبر
  \item پیش‌بینیِ برازندگی برای همه نامزدها با \lr{KNN}
  \item مرتب‌سازی بر اساسِ امتیازِ ترکیبی (بهره‌برداری + تازگی)
  \item گزینشِ 85\% برتر به‌واسطه بهره‌برداری
  \item گزینشِ 15\% برترِ باقی‌مانده به‌واسطه تازگی
  \item ارزیابیِ واقعیِ گزیده‌ها و به‌روزرسانی مدل
  \item \textbf{بازگشت}: افرادِ ارزیابی‌شده
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsubsection{تولید مخزن نامزد}

\begin{algorithm}
\caption{تولید مخزن نامزد}
\begin{enumerate}
\item \textbf{تابع} \texttt{generate\_candidate\_pool(individuals, pool\_factor)}:
  \begin{enumerate}
  \item \(pool \leftarrow \emptyset\)
  \item \textbf{برای هر} فرد:
    \begin{enumerate}
    \item افزودن نسخه اصلی به مخزن
    \item \textbf{برای} \(i=1\) تا \texttt{pool\_factor}:
      \begin{enumerate}
      \item کپی‌برداری و اغتشاشِ هر پارامتر با \(\mathcal{N}(0,\; 0.1\times \mtext{range})\)
      \item بستن پارامترها به کران‌های معتبر
      \item افزودن به مخزن
      \end{enumerate}
    \end{enumerate}
  \item \textbf{بازگشت}: \texttt{pool}
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{راهبردهای بذرگذاری پیشرفته}

چند راهبرد بذرگذاری برای آغاز جمعیت پیاده‌سازی شده که نسبت به تصادفی، پوششِ بهتری از فضای پارامتر می‌دهند.

\subsubsection{دنباله سوبول}

نمونه‌برداریِ شبه‌تصادفی با واگراییِ پایین:
\begin{equation}\label{Eq.sobol_sequence}
x_{i,j} = x_{L,j} + (x_{U,j} - x_{L,j}) \cdot s_{i,j}
\end{equation}
که \(s_{i,j}\) مؤلفه \(j\)ـامِ نقطه \(i\)ـامِ دنباله سوبولِ نرمال‌شده به \([0,1]\) است.

\subsubsection{نمونه‌برداریِ هایپِرکیوب لاتین (\lr{LHS})}

\lr{LHS} یکنواختی پوششِ هر بُعد را تضمین می‌کند:
\begin{equation}\label{Eq.lhs_sampling}
x_{i,j} = x_{L,j} + (x_{U,j} - x_{L,j}) \cdot \frac{\pi_j(i) + U_i}{N}
\end{equation}
که \(\pi_j\) یک جایگَشتِ تصادفی در بُعدِ \(j\)، \(U_i \sim U(0,1)\) و \(N\) اندازه جمعیت است.

\subsubsection{الگوریتم یکپارچه‌سازی}

\begin{algorithm}
\caption{مقداردهیِ اولیه پیشرفته جمعیت}
\begin{enumerate}
\item \textbf{تابع} \texttt{generate\_seed\_individuals(count)}:
  \begin{enumerate}
  \item \textbf{اگر} \texttt{seeding\_method == "sobol"}:
    \begin{enumerate}
    \item آغازگر سوبول
    \item \textbf{برای} \(i=1\) تا \texttt{count}: دریافت نقطه بعدی، نگاشت به \([x_L,x_U]\)، ساخت فرد
    \end{enumerate}
  \item \textbf{وگرنه اگر} \texttt{seeding\_method == "lhs"}:
    \begin{enumerate}
    \item ساخت طرح \lr{LHS} و تولید \texttt{count} فرد
    \end{enumerate}
  \item \textbf{در غیر این‌صورت} (تصادفی): نمونه‌گیری یکنواخت در \([x_L,x_U]\) برای هر پارامتر
  \item \textbf{بازگشت}: فهرست افراد
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{کنترل تطبیقیِ نرخ‌ها}

این سامانه، نرخ‌های ترکـیب و جهش را بر پایه تنوعِ جمعیت و پیشرفتِ بهینه‌سازی به‌طور پویا تنظیم می‌کند.

\subsubsection{سنجش تنوع}

تنوعِ نرمال‌شده جمعیت از آمارِ برازندگی به‌دست می‌آید:
\begin{equation}\label{Eq.diversity_measure}
D = \frac{1}{N} \sum_{i=1}^{N} \left(\frac{f_i - \bar{f}}{\sigma_f + \epsilon}\right)^{\!2}
\end{equation}
که \(f_i\) برازندگیِ فرد، \(\bar{f}\) میانگین و \(\sigma_f\) انحراف معیار است.

\subsubsection{قواعد تطبیقی}

\begin{itemize}
\item \textbf{تنوع پایین} (\(D<0.1\)): افزایش جهش، کاهش ترکـیب (تقویت اکتشاف)
\item \textbf{تنوع بالا} (\(D>0.3\)): افزایش ترکـیب، کاهش جهش (تقویت بهره‌برداری)
\item \textbf{تنوع متوسط}: تناوب بین دو راهبردِ بالا
\end{itemize}

\subsubsection{الگوریتم یکپارچه‌سازی}

\begin{algorithm}
\caption{کنترل تطبیقیِ نرخ‌ها}
\begin{enumerate}
\item \textbf{تابع} \texttt{adapt\_rates(pop, current\_cx, current\_mu)}:
  \begin{enumerate}
  \item محاسبه \(\bar{f}\)، \(\sigma_f\) و \(D \leftarrow \min(1.0,\; \sigma_f/\bar{f})\) (اگر \(\bar{f}>0\)، وگرنه \(0.5\))
  \item \textbf{اگر} \(D<0.1\): \(\mu_{\mtext{new}} \leftarrow \min(\mu_{\max},\, 1.5\,\mtext{current\_mu})\)، \(cx_{\mtext{new}} \leftarrow \max(cx_{\min},\, 0.8\,\mtext{current\_cx})\)
  \item \textbf{وگرنه اگر} \(D>0.3\): \(cx_{\mtext{new}} \leftarrow \min(cx_{\max},\, 1.5\,\mtext{current\_cx})\)، \(\mu_{\mtext{new}} \leftarrow \max(\mu_{\min},\, 0.8\,\mtext{current\_mu})\)
  \item \textbf{وگرنه} (متوسط): در نسل‌های زوج \((\uparrow cx,\downarrow \mu)\) و در فرد \((\downarrow cx,\uparrow \mu)\)
  \item \textbf{بازگشت}: \(cx_{\mtext{new}},\, \mu_{\mtext{new}},\, \texttt{strategy}\)
  \end{enumerate}
\end{enumerate}
\end{algorithm}

\subsection{نوآوری و جمع‌بندیِ یکپارچه‌سازی}

یکپارچه‌سازی این ویژگی‌های پیشرفته، نوآوریِ قابل‌توجهی در محاسباتِ تکاملی برای بهینه‌سازی \lr{DVA} محسوب می‌شود. این سامانه چندین سازوکارِ تطبیقی را توأمان به‌کار می‌گیرد:
\begin{enumerate}
\item \textbf{تطبیق چندسطحی}: کنترل‌گر \lr{RL} و کنترلِ تطبیقیِ نرخ‌ها دو لایه مکمل از سازگارسازی را فراهم می‌کنند.
\item \textbf{بذرگذاریِ هوشمند}: شبکه‌های عصبی و طرح‌های نمونه‌برداریِ پیشرفته، کیفیتِ جمعیت را بهبود می‌دهند.
\item \textbf{ارزیابیِ هوشمند}: مدل‌های جانشین هزینه محاسبات را می‌کاهند و کارایی جست‌وجو را حفظ می‌کنند.
\item \textbf{یادگیریِ برخط}: همه مؤلفه‌ها حین اجرا می‌آموزند و سازگار می‌شوند.
\item \textbf{پایش جامع}: سنجه‌های دقیق، عملکردِ هر مؤلفه تطبیقی را رصد می‌کنند.
\end{enumerate}

این رهیافتِ یکپارچه با فراهم‌کردن کنترلِ هوشمند و تطبیقی بر تمامِ جنبه‌های فرآیند تکاملی، به محدودیت‌های بنیادیِ \lr{GA}‌های سنتی پاسخ می‌دهد و امکان کاوشِ مؤثرِ فضای 48بُعدیِ پارامترهای \lr{DVA} را با حفظ کارایی محاسباتی و دست‌یابی به کیفیتِ بالای راه‌حل فراهم می‌سازد.
